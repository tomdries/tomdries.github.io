---
title: "LLMs are changing how we write. Maybe that's a good thing."
description: "A reflection on using generative AI in academic writing"
pubDate: "February 11 2025"
heroImage: "/images/chatgpt.jpg"
tags: ["phd"]
---
*In this post I reflect on the use of LLMs for scientific writing and coding. It is also included in the conclusion section of my PhD dissertation, in slightly different form, which is currently under review.*

The period in which my dissertation was written (late 2020–early 2025) spans a unique time period regarding the general adoption of generative AI. Approximately in the middle, November 2022, ChatGPT was released to a wide audience. By the end of the period, such models outperform humans in many tasks (<a href="https://doi.org/10.3390/computers13110278" target="_blank">De Winter et al., 2024a</a>; <a href="https://doi.org/10.48550/arxiv.2412.05753" target="_blank">Latif et al., 2024</a>; <a href="https://doi.org/10.1038/s41598-024-79048-0" target="_blank">Mittelstädt et al., 2024</a>; <a href="https://doi.org/10.1007/s11191-024-00496-1" target="_blank">Zhai et al., 2024</a>). 

Although earlier LLM models were already available before this release, they did not yet have the typical chat interaction now common in many applications. From my early interactions with those models, I remember being quite amazed by the fact that computers could come up with such sophisticated human-like completions. Yet, I did not find much practical use for it in my day-to-day activities. The release of ChatGPT changed this.

### LLMs as a productivity aid

When ChatGPT was released, I was immediately able to use it for grammar checks and rewriting awkwardly formulated senences. As a non-native English speaker, this was very welcome. A walk through the hallways of our faculty building showed I was not the only one: many students typically have a window of ChatGPT or other popular LLMs opened. How quickly ChatGPT was adopted was also noticeable as it became common to recognize AI-generated text in papers, emails, and even academic peer reviews that I and colleagues received. Texts often had a similar tone to them and sounded somewhat cliché, molded into the same sentence structure or using similar specific words. Many texts were now "delving" into "comprehensive" analyses, and their "key" and "significant" insights were suddenly leading to "crucial" contributions.

#### Increased productivity or inflation of words?

I noticed that while individual passages encountered were clearer and less repetitive, the overall text, when compared to other AI-assisted writings, had become more uniform and homogenous. It is as if we were all using the same proofreader. This is especially noticeable in unedited LLM output such as the GPT-4 generated summaries used in <a href="https://doi.org/10.3389/fpubh.2024.1352979" target="_blank">our truck driver questionnaire study</a>, that contain for example "key issues", "key points", "key themes", "significant concern(s)" (2x), "a significant contributor", "significant roles" over the span of two pages.

The ability to transform scattered drafts and bullet points into polished texts within seconds also came with other effects. In a way, the value of a piece of text decreases when the perceived effort is lower, which can create a certain sense of meaninglessness to the reader. <a href="https://www.researchgate.net/publication/375742431_ChatGPT_and_academic_work_New_psychological_phenomena" target="_blank">De Winter et al. (2024)</a> used the term *inflation of words* to describe how AI-generated text, while technically proficient, often lacks the inherent value and meaning of human-written content due to large quantities of words becoming available at low cost, or without struggle. Before LLMs, any text offered a window into the author's thought process and understanding. AI-generated text, despite being technically correct, often feels hollow.

However, the appeal of using LLMs for writing seems to outweigh some of the negative aspects. There are widely documented positive effects on productivity in both text and code writing. Besides that, I believe an important positive aspect of current LLMs is that they have the ability to make participation in academia more accessible to a larger group of people.

### Accessibility of academia

Some of the smartest minds I have encountered were fellow students who excelled at math, coding, prototyping, or other hands-on technical skills. Yet many of these same individuals, including some with dyslexia, dreaded the documentation process. They often struggled through their master's thesis writing, despite doing exceptional work. If I were to ask them about pursuing a PhD, they would likely dismiss the idea due to the associated writing demands. And though there are valid reasons to question pursuing an academic career, I believe that adversity towards writing does not need to be one anymore.

Writing research papers has evolved into the primary way to compress and disseminate academic ideas efficiently. I believe that a written traditional research paper remains the format for storing the outcome of empirical research work. It is universal and forces careful consideration of what information to include. However, the path to creating these papers is transforming. Instead of processing several months of work by sitting down and carefully constructing a research paper, authors can now engage in organic, conversation-based workflows with LLMs. 

Through interactions with LLMs, especially longer format conversations with counter-questions for clarity, authors can achieve compression of their ideas with fewer concerns about grammar, style, or writing flow. These interactions can use mixed modalities, such as a mix of raw drafts of paragraphs and bullet points about the author's explanations and ideas, combined with a turn-taking auditory conversation where the LLM asks clarifying questions about the work. The LLM can then help structure these various inputs into coherent academic writing. The researcher can take their turn in verifying the output, and prepare a next iteration. Ideally, this improves the overall rigor and depth expected from research papers, while removing the barriers of writing. 

If writing becomes more approachable and even enjoyable for those who traditionally struggle with it, science as a whole could benefit tremendously. I am personally experiencing more joy in writing, and even more so in coding, when there is always an assistant at hand to have a back-and-forth with, one that displays a certain understanding of the topic and occasionally comes up with creative suggestions to integrate the ideas into a consistent whole. 

I wonder how many potential discoveries have been lost because good thinkers have felt intimidated by the writing process. If the future of academia can be more about the quality of ideas rather than writing ability, by allowing researchers to focus on their talents while using AI to help translate their thoughts into well-structured papers, the gains for scientific progress could be big. 

### The future of generative AI

The experiences and concerns discussed above have mostly been shaped by my interactions with generative AI thus far. However, concerns such as the homogenization of written language are specifically focused on the topic of writing using LLMs, and they pale in comparison to the broader discussion surrounding the consequences of generative AI in the future. Though a full exploration of these potential consequences could fill an entire dissertation, several pressing issues deserve mention.

First, there is the concentration of power in the hands of a few tech companies that own and control these AI systems. They are not just providing a service; they are becoming the gatekeepers of an infrastructure that powers how we write, think, and create. When your work needs to flow through someone else's servers, questions of privacy and control come into play. However, the rapid development of open-source models like <a href="https://doi.org/10.48550/arxiv.2407.21783" target="_blank">Llama</a> and <a href="https://doi.org/10.48550/arXiv.2501.12948" target="_blank">Deepseek</a>, which offer performance comparable to commercial models and can be run locally, suggests advanced models may in the future not always remain proprietary.

A second and perhaps most worrying issue is how cheap and easy it is becoming to deploy armies of intelligent bots. This is not only spam; these are sophisticated systems that can engage in online conversations, shape public opinion, and influence discourse at a scale we have never seen before (<a href="https://www.penguinrandomhouse.com/books/765110/nexus-by-yuval-noah-harari/" target="_blank">Harari, 2024</a>). When artificial voices become indistinguishable from real ones, how do we maintain authentic public dialogue?

#### Autonomous researchers

I have discussed several ways I have used LLMs in my research; as productivity aids for writing and coding, as a productivity aid <a href="https://doi.org/10.3389/fpubh.2024.1352979" target="_blank">within research methods</a>, and as <a href="https://doi.org/10.1098/rsos.231676" target="_blank">a research subject </a>. However, a fourth potential role looms on the horizon: LLMs as independent researchers. While I have had no success using current LLMs for generating truly novel ideas or executing research independently, the pace at which the models are better at executing tasks is striking. 

Having observed the evolution of these models over the past few years, their trajectory of improvement is remarkable. The costs to generate words are dropping very fast. For example, the model used in the truck driver questionnaire (GPT-4-0125-preview), which was the most capable model at the time, cost $30 per million tokens (approximately 1.3 million words) on March 1, 2024 (see the <a href="https://web.archive.org/web/20240304150812/https://openai.com/pricing" target="_blank">Wayback Machine</a>). At the time of writing, less than a year later, on January 27, 2025, a model with superior performance (GPT-4o-mini, according to <a href="https://doi.org/10.48550/arXiv.2403.04132" target="_blank">LMSYS ratings</a>) was available for just $0.60 per million output tokens. And with the release of the aforementioned open-source public models, competetive models can be run locally or on private servers at cost price.

Alongside dropping costs, there is increasing competence of these models. Dario Amodei, CEO of Anthropic--the AI company that released Claude, my model of choice for coding assistance over the past months--predicts that based on his observations within the company, AI could surpass human intelligence <a href="https://www.youtube.com/watch?v=snkOMOjiVOk?t=1197" target="_blank">within several years</a>. Although the history of futuristic predictions by big tech leaders, such as those in automated driving, has taught us to be wary of timeline estimates, these predictions do not seem very shocking in light of the rapid progress of the past several years. 

This potential future raises fundamental questions about the nature of academic research itself. What defines academia when machines can potentially conduct research autonomously? Should certain types of research remain exclusively human domains? These questions might seem premature, but given the pace of AI development, they deserve serious consideration now.